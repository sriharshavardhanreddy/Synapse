{
	"name": "SQL Pool_External_Parquet",
	"properties": {
		"content": {
			"query": "-- Lab - SQL Pool - External Tables - Parquet\n\nCREATE MASTER KEY ENCRYPTION BY PASSWORD = 'P@ssw0rd@123';\n\n-- Here we are using the Storage account key for authorization\n\nCREATE DATABASE SCOPED CREDENTIAL SasToken\nWITH IDENTITY='SHARED ACCESS SIGNATURE'\n, SECRET = 'sv=2022-11-02&ss=b&srt=sco&sp=rwdlacyx&se=2023-12-13T14:19:01Z&st=2023-11-13T06:19:01Z&spr=https&sig=wMHKoL0egX3wqrgBapP2tOIJjuJXfan9DcWNtmMTKvI%3D';\n\n-- When it comes to Dedicated SQL pool\n-- https://learn.microsoft.com/en-us/azure/synapse-analytics/sql/create-use-external-tables\n-- For CSV files, we need to use the Hadoop driver in the TYPE when mentioning the data source\n-- But if we do this, we get the error Hadoop \n-- The native driver is supported for Partquet based files\n\nCREATE EXTERNAL DATA SOURCE log_data_parquet\nWITH (    LOCATION   = 'https://datalake2029.dfs.core.windows.net/parquet',\n          CREDENTIAL = SasToken\n)\n\nCREATE EXTERNAL FILE FORMAT parquetfile  \nWITH (  \n    FORMAT_TYPE = PARQUET,  \n    DATA_COMPRESSION = 'org.apache.hadoop.io.compress.SnappyCodec'  \n);\n\n\nCREATE EXTERNAL TABLE [logdata_parquet]\n(\n    [Correlationid] [varchar](200) NULL,\n\t[Operationname] [varchar](200) NULL,\n\t[Status] [varchar](100) NULL,\n\t[Eventcategory] [varchar](100) NULL,\n\t[Level] [varchar](100) NULL,\n\t[Time] [varchar](500) NULL,\n\t[Subscription] [varchar](200) NULL,\n\t[Eventinitiatedby] [varchar](1000) NULL,\n\t[Resourcetype] [varchar](1000) NULL,\n\t[Resourcegroup] [varchar](1000) NULL,\n    [Resource] [varchar](2000) NULL)\nWITH (\n LOCATION = '/log.parquet',\n    DATA_SOURCE = log_data_parquet,  \n    FILE_FORMAT = parquetfile\n)\n\n\nSELECT * FROM logdata_parquet\n\n",
			"metadata": {
				"language": "sql"
			},
			"currentConnection": {
				"databaseName": "pooldb",
				"poolName": "pooldb"
			},
			"resultLimit": 5000
		},
		"type": "SqlQuery"
	}
}